{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as spstats\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the paper \"On fluctuation analysis: a new, simple and efficient method for computing the expected number of mutants\" by Sarkar, Ma, and Sandri to understand how to calculate the probability mass function for a Luria Delbruck distribution in the limit of rare mutations in a large population. In particular, we also assume that the final population size is much much greater (approximately 1000 fold or more times) than the initial population size since this approximation simplifies things slightly and our initial population sizes in experiments are a 100,000 to 1,000,000 times less than our final population size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class luriaDelbruck(spstats.rv_discrete):\n",
    "    \n",
    "    def __init__(self, a=0, b=np.inf, name=None, badvalue=None, moment_tol=1e-08, values=None, inc=1,\n",
    "                 longname=None, shapes=None, extradoc=None, seed=None):\n",
    "        spstats.rv_discrete.__init__(self, a, b, name, badvalue, moment_tol, values, inc, longname,\n",
    "                                    shapes, extradoc, seed)\n",
    "        self.muNk_dict = {}\n",
    "\n",
    "\n",
    "    # note to self: this implementation needs to be able to take numpy arrays in for k, mu, and N in order for\n",
    "    # scipy.stats machinery to be able to automatically implement the remaining methods for the probability\n",
    "    # distribution correctly.In particular we need the logpdf function to work. Then we can use\n",
    "    # statsmodels to automagically get maximum likelihood estimation and bootstrapping working for free.\n",
    "    def _pmf(self, k, mu, N):\n",
    "        soln = np.zeros_like(k,dtype='float')\n",
    "        mu = np.array(mu).flatten()\n",
    "        N = np.array(N,dtype='int64').flatten()\n",
    "        for index, num in enumerate(k):\n",
    "            if mu.size > 1:\n",
    "                mu_i = mu[index]\n",
    "            else:\n",
    "                mu_i = mu\n",
    "            if N.size > 1:\n",
    "                N_i = N[index]\n",
    "            else:\n",
    "                N_i = N\n",
    "            try:\n",
    "                key = (mu_i*N_i)[0]\n",
    "            except IndexError:\n",
    "                key = mu_i*N_i\n",
    "            if key in self.muNk_dict:\n",
    "                if self.muNk_dict[key].size <= num:\n",
    "                    temp = self.muNk_dict[key]\n",
    "                    self.muNk_dict[key]=-1*np.ones(int(num)+1)\n",
    "                    self.muNk_dict[key][0:temp.size]=temp\n",
    "            else:\n",
    "                self.muNk_dict[key]=-1*np.ones(int(num)+1)\n",
    "            soln[index]= self._xtraprivatepmf(num, mu_i, N_i)\n",
    "        return soln\n",
    "    \n",
    "    #this private implementation of the probability mass function only accepts single numbers not arrays.\n",
    "    #We're stuck with this because we can only compute the pmf recursively.\n",
    "    def _xtraprivatepmf(self, k, mu, N):\n",
    "        try:\n",
    "            key = (mu*N)[0]\n",
    "        except IndexError:\n",
    "            key = mu*N\n",
    "        k=int(k)\n",
    "        if self.muNk_dict[key][k] == -1:\n",
    "            if k == 0:\n",
    "                self.muNk_dict[key][k] = np.exp(-mu*N)\n",
    "            else:\n",
    "                prev_results = []\n",
    "                for i in range(0,k):\n",
    "                    prev_results.append(self._xtraprivatepmf(i, mu, N)/(k-i+1))\n",
    "                self.muNk_dict[key][k] = mu*N/k * np.sum(np.array(prev_results))\n",
    "        return self.muNk_dict[key][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler = luriaDelbruck()\n",
    "mu_s = 10**-8\n",
    "N_little = 10**8\n",
    "Ratio = 10\n",
    "N_big = Ratio*N_little\n",
    "sample_size = (10,10)\n",
    "test_sample = sampler.rvs(mu_s,N_little,size=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 15.49 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 3: 189 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit test_sample_big = sampler.rvs(mu_s,N_big,size=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_pmf():\n",
    "    sampler = luriaDelbruck()\n",
    "    ans = sampler.pmf(np.arange(5000),10**-7,10**8)\n",
    "    print(ans[4999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.12472741338e-07\n",
      "4.12472741338e-07\n",
      "4.12472741338e-07\n",
      "4.12472741338e-07\n",
      "1 loop, best of 3: 29.3 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit time_pmf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample_big_plated = np.random.poisson(test_sample_big/Ratio)\n",
    "print(test_sample)\n",
    "print(test_sample_big_plated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_sample_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians_little = np.median(test_sample,axis=0)\n",
    "medians_big_plated = np.median(test_sample_big_plated,axis=0)\n",
    "print(medians_little)\n",
    "print(medians_big_plated)\n",
    "print('the fold difference between highest and lowest medians in current procedure is',\n",
    "      np.max(medians_little)/np.min(medians_little))\n",
    "print('the fold difference between highest and lowest medians in new procedure is',\n",
    "      np.max(medians_big_plated)/np.min(medians_big_plated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SarkarMaSandri(GenericLikelihoodModel):\n",
    "\n",
    "    \n",
    "    def __init__(self, endog, exog, **kwds):\n",
    "        super(SarkarMaSandri, self).__init__(endog, exog, **kwds)\n",
    "        self.luria_delbruck = luriaDelbruck()\n",
    "\n",
    "\n",
    "    def nloglikeobs(self, params):\n",
    "        mu = params[0]\n",
    "        return -np.sum(np.log(self.luria_delbruck.pmf(self.endog, mu, self.exog)))\n",
    "\n",
    "\n",
    "    def fit(self, start_params=None, maxiter=10000, maxfun=50, **kwds):\n",
    "        if start_params == None:\n",
    "            mu_start = np.sum(endog)/np.sum(exog)\n",
    "            start_params = mu_start\n",
    "        return super(SarkarMaSandri, self).fit(start_params=start_params,\n",
    "                     maxiter=maxiter, maxfun=maxfun, **kwds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endog = test_sample_big[3] #rifampicin plates\n",
    "exog = np.ones(sample_size[0])*N_big #LB plates\n",
    "estimator_test = SarkarMaSandri(endog, exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = estimator_test.fit()\n",
    "print('the estimated mutation rate is', results.params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_test.hessian(np.array([6.5*10**-9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_test.luria_delbruck._pmf(estimator_test.endog, np.ones_like(estimator_test.endog)*1.2*10**-8,\n",
    "                                   estimator_test.exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.tools.numdiff as stnud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stnud.approx_hess(np.array([1.2*10**-8]), estimator_test.loglike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 1.89*10**-8\n",
    "probs = ldcheck.pmf(endog, mu, exog)\n",
    "print(-np.sum(np.log(probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(endog)/np.sum(exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rif_plates_exp_1 = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,3,2,1,8,4,3,2,9,6,30,40,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = .062 * 10**(-7)\n",
    "N = (51+22+23+45+59)/5*2.5*10**6\n",
    "likelihoods = ldcheck.pmf(rif_plates_exp_1, mu, N)\n",
    "loglikelihood = np.log(likelihoods)\n",
    "print(np.sum(loglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = .034 * 10**(-7)\n",
    "N = (51+22+23+45+59)/5*2.5*10**6\n",
    "likelihoods = ldcheck.pmf(rif_plates_exp_1, mu, N)\n",
    "loglikelihood = np.log(likelihoods)\n",
    "print(np.sum(loglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = .096 * 10**(-7)\n",
    "N = (51+22+23+45+59)/5*2.5*10**6\n",
    "likelihoods = ldcheck.pmf(rif_plates_exp_1, mu, N)\n",
    "loglikelihood = np.log(likelihoods)\n",
    "print(np.sum(loglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = .034 * 10**(-8)\n",
    "N = (51+22+23+45+59)/5*2.5*10**6\n",
    "likelihoods = ldcheck.pmf(rif_plates_exp_1, mu, N)\n",
    "loglikelihood = np.log(likelihoods)\n",
    "print(np.sum(loglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = .096 * 10**(-6)\n",
    "N = (51+22+23+45+59)/5*2.5*10**6\n",
    "likelihoods = ldcheck.pmf(rif_plates_exp_1, mu, N)\n",
    "loglikelihood = np.log(likelihoods)\n",
    "print(np.sum(loglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rif_plates_exp_2 = [0,0,0,0,0,0,0,0,0,0,0,0,0,14,100,1,1,2,2,2,1,13,6,9,2,11,62,22,8,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = .079 * 10**(-7)\n",
    "N = (61+17+78+37)/4*2.5*10**6\n",
    "likelihoods = ldcheck.pmf(rif_plates_exp_2, mu, N)\n",
    "loglikelihood = np.log(likelihoods)\n",
    "print(np.sum(loglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = .048 * 10**(-7)\n",
    "N = (61+17+78+37)/4*2.5*10**6\n",
    "likelihoods = ldcheck.pmf(rif_plates_exp_2, mu, N)\n",
    "loglikelihood = np.log(likelihoods)\n",
    "print(np.sum(loglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = .117 * 10**(-7)\n",
    "N = (61+17+78+37)/4*2.5*10**6\n",
    "likelihoods = ldcheck.pmf(rif_plates_exp_2, mu, N)\n",
    "loglikelihood = np.log(likelihoods)\n",
    "print(np.sum(loglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(np.array(np.array([1],dtype='int64'))).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
